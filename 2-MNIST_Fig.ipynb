{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main figures in \"Top-down connection in hierarchical sparse coding\" for the MNIST database\n",
    "https://arxiv.org/abs/2002.00892"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPC_2L.DataTools import DataBase, to_img, show\n",
    "import pickle\n",
    "from SPC_2L.Network import LayerPC, Network\n",
    "from SPC_2L.Coding import ML_FISTA, ML_Lasso\n",
    "import torch.nn.functional as f\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.utils import make_grid\n",
    "import torch\n",
    "from torchvision.transforms import ToTensor,Compose\n",
    "from SPC_2L.DataTools import LCN, whitening, z_score, mask, to_cuda, norm\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools, parameters and database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction(Net,gamma):\n",
    "    reco = [None] * (Net.nb_layers)\n",
    "    for i in range(Net.nb_layers-1,-1,-1):\n",
    "        reco[i] = gamma[i]\n",
    "        for j in range(i, -1, -1):\n",
    "            reco[i] = Net.layers[j].backward(reco[i])\n",
    "    return reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1145da560983>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     z_score()])\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mDataBase\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             raise RuntimeError('Dataset not found.' +\n\u001b[0;32m---> 50\u001b[0;31m                                ' You can use download=True to download it')\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dataset not found. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "data_path = '../DataSet/MNIST/'\n",
    "\n",
    "transform = Compose([ToTensor(),\n",
    "                    to_cuda(),\n",
    "                    whitening((28,28),f_0=0.6),\n",
    "                    LCN(kernel_size=3,sigma=0.5,rgb=False),\n",
    "                    z_score()])\n",
    "\n",
    "dataset = MNIST(data_path, transform=transform, train=False, download=False)\n",
    "\n",
    "DataBase =  DataLoader(dataset,batch_size=32,shuffle=True,drop_last=True)\n",
    "\n",
    "save = False #### Use to re-run the entire simulation : TAKE HOURS. Use False to load previous simulation\n",
    "\n",
    "range_b = [0,1] ## b=0 --> HiLa, b=1 --> 2L_SPC\n",
    "range_lbda1 = [0.10 + i*0.05 for i in range(5)] ## range of tested lbda1\n",
    "range_lbda2 = [0.20 + i*0.05 for i in range(5)] ## range of tested lbda2\n",
    "\n",
    "model_name_list_l1_b0 = ['MNIST_[{0:0.2f},0.30]_b={1:0.0f}'.format(lbda1,0) for lbda1 in range_lbda1]\n",
    "model_name_list_l2_b0 = ['MNIST_[0.20,{0:0.2f}]_b={1:0.0f}'.format(lbda2,0) for lbda2 in range_lbda2]\n",
    "\n",
    "model_name_list_l1_b1 = ['MNIST_[{0:0.2f},0.30]_b={1:0.0f}'.format(lbda1,1) for lbda1 in range_lbda1]\n",
    "model_name_list_l2_b1 = ['MNIST_[0.20,{0:0.2f}]_b={1:0.0f}'.format(lbda2,1) for lbda2 in range_lbda2]\n",
    "\n",
    "\n",
    "cmap1=plt.get_cmap('tab20c')\n",
    "cmap2=plt.get_cmap('tab20b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save == True: Wrapping all  the exploration space in one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_list = {'MNIST_lbda1' : (model_name_list_l1_b0, model_name_list_l1_b1),\n",
    "          'MNIST_lbda2' : (model_name_list_l2_b0, model_name_list_l2_b1)\n",
    "         }\n",
    "\n",
    "if save == True : \n",
    "    for exp_idx, exp_name in enumerate(exp_list.keys()):\n",
    "        print('Exp {0} : {1}'.format(exp_idx,exp_name))\n",
    "        file_to_save = 'Savings/MNIST/' + str(exp_name) + '.pkl'\n",
    "        \n",
    "        Layer_wise_loss_SDPC = np.zeros((len(range_b),len(model_name_list_l1_b0), 2))\n",
    "        it_SDPC = np.zeros((len(range_b),len(model_name_list_l1_b0)))\n",
    "        all_L2_loss = np.zeros((len(range_b),len(model_name_list_l1_b0), 2))\n",
    "        all_L1_loss = np.zeros((len(range_b),len(model_name_list_l1_b0), 2))\n",
    "\n",
    "        for idx_b, b in enumerate(range_b):\n",
    "        \n",
    "            for idx_model, model_name in enumerate(exp_list[exp_name][idx_b]):\n",
    "                print(model_name)\n",
    "                path = 'Savings/MNIST/' + model_name +'.pkl'\n",
    "\n",
    "                with open(path, 'rb') as file:\n",
    "                    out = pickle.load(file)\n",
    "                Net = out['Net']\n",
    "                print(Net.layers[0].b)\n",
    "                Loss = out['Loss']\n",
    "                Pursuit = out['Pursuit'] \n",
    "                all_error = [0] * (Net.nb_layers)\n",
    "                all_it = 0\n",
    "                all_Loss = [0] * (Net.nb_layers)\n",
    "                penalty = [None] * (Net.nb_layers)\n",
    "                all_penalty = [0] * (Net.nb_layers)\n",
    "                for idx_batch, data in enumerate(DataBase):\n",
    "                    batch = data[0].cuda()\n",
    "                    if idx_batch>20:\n",
    "                        break\n",
    "                    gamma, it, Loss_G, delta = Pursuit.coding(batch)\n",
    "                    reco = reconstruction(Net,gamma)\n",
    "                    error = [(((data[0].cuda() - reco[i]).pow(2).sum())/(data[0].cuda().pow(2).sum())) for i in range(Net.nb_layers)]\n",
    "                    for i in range(Net.nb_layers):\n",
    "                        all_Loss[i] += Loss.F(batch,gamma,i, do_feedback=False).div(batch.size()[0])\n",
    "\n",
    "                    penalty = [Loss.lambdas[i]*gamma[i].abs().sum() for i in range(Net.nb_layers)]\n",
    "\n",
    "                    for i in range(Net.nb_layers):\n",
    "                        all_error [i] += error[i]\n",
    "                    for i in range(Net.nb_layers):\n",
    "                        all_penalty[i] += penalty[i]\n",
    "                    all_it += it        \n",
    "\n",
    "                print('idx_batch',idx_batch)\n",
    "\n",
    "                for i in range(Net.nb_layers):\n",
    "                    all_error[i] /= ((idx_batch+1)*batch.size(0))\n",
    "                for i in range(Net.nb_layers):\n",
    "                    all_Loss[i] /= ((idx_batch+1))    \n",
    "                for i in range(Net.nb_layers):\n",
    "                    all_penalty[i] /= ((idx_batch+1)*batch.size(0))    \n",
    "                all_it /= (idx_batch+1)\n",
    "                tot_loss = 0\n",
    "                for i in range(Net.nb_layers):\n",
    "                    tot_loss += all_Loss[i]+all_penalty[i]\n",
    "                    Layer_wise_loss_SDPC[idx_b, idx_model,i]=all_Loss[i]+all_penalty[i]\n",
    "                    all_L2_loss[idx_b, idx_model,i] = all_Loss[i]\n",
    "                    all_L1_loss[idx_b, idx_model, i] = all_penalty[i]\n",
    "                it_SDPC[idx_b, idx_model] = all_it \n",
    "            res_SDPC = {'loss': Layer_wise_loss_SDPC,\n",
    "                      'it': it_SDPC,\n",
    "                        'L2_loss':all_L2_loss,\n",
    "                        'L1_loss':all_L1_loss}\n",
    "            with open(file_to_save, 'wb') as file:\n",
    "                pickle.dump(res_SDPC, file, pickle.HIGHEST_PROTOCOL)\n",
    "        else : \n",
    "            with open(file_to_save, 'rb') as file:\n",
    "                res_SDPC = pickle.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Savings/MNIST/MNIST_lbda1.pkl', 'rb') as file:\n",
    "        res_exp_lbda1 = pickle.load(file)\n",
    "        \n",
    "with open('Savings/MNIST/MNIST_lbda2.pkl', 'rb') as file:\n",
    "        res_exp_lbda2 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig = True\n",
    "\n",
    "width = 0.75 \n",
    "fontsize = 20\n",
    "## Plotting reconsctruction error when increasing lbda1\n",
    "N = res_exp_lbda1['loss'].shape[1]\n",
    "position_SDPC = [2 + 3*i for i in range(N)] \n",
    "position_HiLa = [1 + 3*i for i in range(N)] \n",
    "SPDC_l2norm_L1_lbda1 = res_exp_lbda1['L2_loss'][1,:,0]\n",
    "SPDC_l2norm_L2_lbda1 = res_exp_lbda1['L2_loss'][1,:,1]\n",
    "SPDC_l1norm_L1_lbda1 = res_exp_lbda1['L1_loss'][1,:,0]\n",
    "SPDC_l1norm_L2_lbda1 = res_exp_lbda1['L1_loss'][1,:,1]\n",
    "\n",
    "HiLa_l2norm_L1_lbda1 = res_exp_lbda1['L2_loss'][0,:,0]\n",
    "HiLa_l2norm_L2_lbda1 = res_exp_lbda1['L2_loss'][0,:,1]\n",
    "HiLa_l1norm_L1_lbda1 = res_exp_lbda1['L1_loss'][0,:,0]\n",
    "HiLa_l1norm_L2_lbda1 = res_exp_lbda1['L1_loss'][0,:,1]\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "p_SDPC__l2norm_L1 = plt.bar(position_SDPC, SPDC_l2norm_L1_lbda1,\n",
    "                    width, color=cmap1(1))#, edgecolor=cmap2(0))\n",
    "p_SDPC_l2norm_L2 = plt.bar(position_SDPC, SPDC_l2norm_L2_lbda1,\n",
    "                    width, color=cmap1(3),bottom= SPDC_l2norm_L1_lbda1)#, edgecolor=cmap2(0),\n",
    "                   \n",
    "p_SDPC_l1norm_L1= plt.bar(position_SDPC, SPDC_l1norm_L1_lbda1,\n",
    "                    width, bottom=SPDC_l2norm_L2_lbda1+SPDC_l2norm_L1_lbda1,color='white'\n",
    "                           ,edgecolor=cmap1(1), hatch='///')#, color=cmap1(3), edgecolor=cmap2(0),\n",
    "\n",
    "p_SDPC_l1norm_L2 = plt.bar(position_SDPC, SPDC_l1norm_L2_lbda1,\n",
    "                    width, bottom=SPDC_l2norm_L2_lbda1+SPDC_l2norm_L1_lbda1+SPDC_l1norm_L1_lbda1,\n",
    "                           color='white',edgecolor=cmap1(3), hatch='///')#, color=cmap1(3), edgecolor=cmap2(0),\n",
    "\n",
    "\n",
    "p_edges_SDPC = plt.bar(position_SDPC, SPDC_l2norm_L1_lbda1+SPDC_l2norm_L2_lbda1+SPDC_l1norm_L2_lbda1+SPDC_l1norm_L1_lbda1,\n",
    "                    width,color='none',edgecolor='black')\n",
    "\n",
    "p_HiLa_l2norm_L1 = plt.bar(position_HiLa, HiLa_l2norm_L1_lbda1, width ,color=cmap2(5))\n",
    "p_HiLa_l2norm_L2 = plt.bar(position_HiLa, HiLa_l2norm_L2_lbda1, width, color=cmap2(7),\n",
    "                   bottom=HiLa_l2norm_L1_lbda1)\n",
    "p_HiLa_l1norm_L1 = plt.bar(position_HiLa, HiLa_l1norm_L1_lbda1, width, color='white',\n",
    "                   bottom=HiLa_l2norm_L1_lbda1+HiLa_l2norm_L2_lbda1, edgecolor=cmap2(5),\n",
    "                    hatch='///')\n",
    "p_HiLa_l1norm_L2 = plt.bar(position_HiLa, HiLa_l1norm_L2_lbda1, width, color='white',\n",
    "                   bottom=HiLa_l2norm_L1_lbda1+HiLa_l2norm_L2_lbda1+HiLa_l1norm_L1_lbda1,\n",
    "                    edgecolor=cmap2(7), hatch='///')\n",
    "\n",
    "p_edges_HiLa = plt.bar(position_HiLa, HiLa_l2norm_L1_lbda1+HiLa_l2norm_L2_lbda1+HiLa_l1norm_L2_lbda1+HiLa_l1norm_L1_lbda1,\n",
    "                    width,color='none',edgecolor='black')\n",
    "\n",
    "\n",
    "plt.ylabel('Cost', fontsize=fontsize, labelpad=10)\n",
    "plt.title('iii) - MNIST', fontsize=fontsize)\n",
    "#plt.title('Evolution Layer-wise loss in SDPC and Hi-La network \\n when varying the second layer sparsity')\n",
    "xticks_position = [1.5 +3*i for i in range(N)]\n",
    "plt.xlabel(r\"$\\lambda_{1}$\", fontsize=fontsize, labelpad=10)\n",
    "plt.yticks([0,40,80,120],fontsize=fontsize)\n",
    "plt.xticks(xticks_position,['{0:0.1f}'.format(lbda1) for lbda1 in range_lbda1]\n",
    "           , fontsize=fontsize)\n",
    "\n",
    "if save_fig:\n",
    "    #plt.savefig('Savings/Fig/Fig2/MNIST_lbda1.png', bbox_inches = 'tight', pad_inches = 0.1, dpi=400)\n",
    "    plt.savefig('Savings/Fig/Fig2/MNIST_lbda1.pdf', bbox_inches = 'tight', pad_inches = 0.1, format='pdf')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "\n",
    "## Plotting reconsctruction error when increasing lbda2\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "N = res_exp_lbda2['loss'].shape[1]\n",
    "position_SDPC = [2 + 3*i for i in range(N)] \n",
    "position_HiLa = [1 + 3*i for i in range(N)] \n",
    "\n",
    "SPDC_l2norm_L1_lbda2 = res_exp_lbda2['L2_loss'][1,:,0]\n",
    "SPDC_l2norm_L2_lbda2 = res_exp_lbda2['L2_loss'][1,:,1]\n",
    "SPDC_l1norm_L1_lbda2 = res_exp_lbda2['L1_loss'][1,:,0]\n",
    "SPDC_l1norm_L2_lbda2 = res_exp_lbda2['L1_loss'][1,:,1]\n",
    "\n",
    "HiLa_l2norm_L1_lbda2 = res_exp_lbda2['L2_loss'][0,:,0]\n",
    "HiLa_l2norm_L2_lbda2 = res_exp_lbda2['L2_loss'][0,:,1]\n",
    "HiLa_l1norm_L1_lbda2 = res_exp_lbda2['L1_loss'][0,:,0]\n",
    "HiLa_l1norm_L2_lbda2 = res_exp_lbda2['L1_loss'][0,:,1]\n",
    "\n",
    "\n",
    "p_SDPC__l2norm_L1 = plt.bar(position_SDPC, SPDC_l2norm_L1_lbda2,\n",
    "                    width, color=cmap1(1))#, edgecolor=cmap2(0))\n",
    "p_SDPC_l2norm_L2 = plt.bar(position_SDPC, SPDC_l2norm_L2_lbda2,\n",
    "                    width, color=cmap1(3),bottom= SPDC_l2norm_L1_lbda2)#, edgecolor=cmap2(0),\n",
    "                   \n",
    "p_SDPC_l1norm_L1= plt.bar(position_SDPC, SPDC_l1norm_L1_lbda2,\n",
    "                    width, bottom=SPDC_l2norm_L2_lbda2+SPDC_l2norm_L1_lbda2,color='white'\n",
    "                           ,edgecolor=cmap1(1), hatch='///')#, color=cmap1(3), edgecolor=cmap2(0),\n",
    "                   #bottom= SPDC_L1_lbda2)\n",
    "\n",
    "p_SDPC_l1norm_L2 = plt.bar(position_SDPC, SPDC_l1norm_L2_lbda2,\n",
    "                    width, bottom=SPDC_l2norm_L2_lbda2+SPDC_l2norm_L1_lbda2+SPDC_l1norm_L1_lbda2,\n",
    "                           color='white',edgecolor=cmap1(3), hatch='///')#, color=cmap1(3), edgecolor=cmap2(0),\n",
    "                #bottom= SPDC_L1_lbda2)\n",
    "#plt.hist(gaussian_numbers, edgecolor='black', linewidth=1.2)\n",
    "\n",
    "p_edges_SDPC = plt.bar(position_SDPC, SPDC_l2norm_L1_lbda2+SPDC_l2norm_L2_lbda2+SPDC_l1norm_L2_lbda2+SPDC_l1norm_L1_lbda2,\n",
    "                    width,color='none',edgecolor='black')\n",
    "\n",
    "p_HiLa_l2norm_L1 = plt.bar(position_HiLa, HiLa_l2norm_L1_lbda2, width ,color=cmap2(5))\n",
    "p_HiLa_l2norm_L2 = plt.bar(position_HiLa, HiLa_l2norm_L2_lbda2, width, color=cmap2(7),\n",
    "                   bottom=HiLa_l2norm_L1_lbda2)\n",
    "p_HiLa_l1norm_L1 = plt.bar(position_HiLa, HiLa_l1norm_L1_lbda2, width, color='white',\n",
    "                   bottom=HiLa_l2norm_L1_lbda2+HiLa_l2norm_L2_lbda2, edgecolor=cmap2(5),\n",
    "                    hatch='///')\n",
    "p_HiLa_l1norm_L2 = plt.bar(position_HiLa, HiLa_l1norm_L2_lbda2, width, color='white',\n",
    "                   bottom=HiLa_l2norm_L1_lbda2+HiLa_l2norm_L2_lbda2+HiLa_l1norm_L1_lbda2,\n",
    "                    edgecolor=cmap2(7), hatch='///')\n",
    "\n",
    "p_edges_HiLa = plt.bar(position_HiLa, HiLa_l2norm_L1_lbda2+HiLa_l2norm_L2_lbda2+HiLa_l1norm_L2_lbda2+HiLa_l1norm_L1_lbda2,\n",
    "                    width,color='none',edgecolor='black')\n",
    "\n",
    "\n",
    "plt.ylabel('Cost', fontsize=fontsize, labelpad=10)\n",
    "plt.title('iii) - MNIST', fontsize=fontsize)\n",
    "#plt.title('Evolution Layer-wise loss in SDPC and Hi-La network \\n when varying the second layer sparsity')\n",
    "xticks_position = [1.5 +3*i for i in range(N)]\n",
    "plt.xlabel(r\"$\\lambda_{2}$\", fontsize=fontsize, labelpad=10)\n",
    "plt.yticks([0,40,80,120],fontsize=fontsize)\n",
    "plt.xticks(xticks_position,['{0:0.1f}'.format(lbda2) for lbda2 in range_lbda2] \n",
    "           , fontsize=15)\n",
    "\n",
    "\n",
    "if save_fig:\n",
    "    #plt.savefig('Savings/Fig/Fig2/MNIST_lbda2.png', bbox_inches = 'tight', pad_inches = 0.1, dpi=400)\n",
    "    plt.savefig('Savings/Fig/Fig2/MNIST_lbda2.pdf', bbox_inches = 'tight', pad_inches = 0.1, format='pdf')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute variation \n",
    "\n",
    "SPDC_l2norm_L1_lbda1 = res_exp_lbda1['L2_loss'][1,:,0]\n",
    "HiLa_l2norm_L1_lbda1 = res_exp_lbda1['L2_loss'][0,:,0]\n",
    "SPDC_l2norm_L2_lbda1 = res_exp_lbda1['L2_loss'][1,:,1]\n",
    "HiLa_l2norm_L2_lbda1 = res_exp_lbda1['L2_loss'][0,:,1]\n",
    "\n",
    "print('QUADRATIC COST')\n",
    "var = ((SPDC_l2norm_L1_lbda1/HiLa_l2norm_L1_lbda1) - 1).mean()\n",
    "print('1st layer SDPC/HiLa (average) : {0:2} %'.format(var*100))\n",
    "\n",
    "var = ((SPDC_l2norm_L2_lbda1/HiLa_l2norm_L2_lbda1) - 1).mean()\n",
    "print('2nd layer SDPC/HiLa (average) : {0:2} %'.format(var*100))\n",
    "\n",
    "var = ((HiLa_l2norm_L1_lbda1[-1]/HiLa_l2norm_L1_lbda1[0]) - 1)\n",
    "print('First Layer HiLa high_lbda_1 / low_lbda_1 : {0:0.2f} %'.format(var*100))\n",
    "\n",
    "var = ((SPDC_l2norm_L1_lbda1[-1]/SPDC_l2norm_L1_lbda1[0]) - 1)\n",
    "print('First Layer SDPC high_lbda_1 / low_lbda_1 : {0:0.2f} %'.format(var*100))\n",
    "\n",
    "\n",
    "print('SPARSITY COST')\n",
    "\n",
    "SPDC_l1norm_L1_lbda1 = res_exp_lbda1['L1_loss'][1,:,0]\n",
    "HiLa_l1norm_L1_lbda1 = res_exp_lbda1['L1_loss'][0,:,0]\n",
    "SPDC_l1norm_L2_lbda1 = res_exp_lbda1['L1_loss'][1,:,1]\n",
    "HiLa_l1norm_L2_lbda1 = res_exp_lbda1['L1_loss'][0,:,1]\n",
    "\n",
    "var = ((HiLa_l1norm_L1_lbda1[-1]/HiLa_l1norm_L1_lbda1[0]) - 1)\n",
    "print('First Layer HiLa high_lbda_1 / low_lbda_1 : {0:0.2f} %'.format(var*100))\n",
    "\n",
    "var = ((SPDC_l1norm_L1_lbda1[-1]/SPDC_l1norm_L1_lbda1[0]) - 1)\n",
    "print('First Layer SDPC high_lbda_1 / low_lbda_1 : {0:0.2f} %'.format(var*100))\n",
    "\n",
    "\n",
    "print('QUADRATIC COST')\n",
    "\n",
    "SPDC_l1norm_L1_lbda2 = res_exp_lbda2['L2_loss'][1,:,0]\n",
    "HiLa_l1norm_L1_lbda2 = res_exp_lbda2['L2_loss'][0,:,0]\n",
    "SPDC_l1norm_L2_lbda2 = res_exp_lbda2['L2_loss'][1,:,1]\n",
    "HiLa_l1norm_L2_lbda2 = res_exp_lbda2['L2_loss'][0,:,1]\n",
    "\n",
    "var = ((HiLa_l1norm_L1_lbda2[-1]/HiLa_l1norm_L1_lbda2[0]) - 1)\n",
    "print('First Layer HiLa high_lbda_2 / low_lbda_2 : {0:0.2f} %'.format(var*100))\n",
    "\n",
    "var = ((SPDC_l1norm_L1_lbda2[-1]/SPDC_l1norm_L1_lbda2[0]) - 1)\n",
    "print('First Layer SDPC high_lbda_2 / low_lbda_2 : {0:0.2f} %'.format(var*100))\n",
    "\n",
    "'''\n",
    "\n",
    "print('SPARSITY COST')\n",
    "\n",
    "SPDC_l1norm_L1_lbda2 = res_exp_lbda2['L2_loss'][1,:,0]\n",
    "HiLa_l1norm_L1_lbda2 = res_exp_lbda2['L2_loss'][0,:,0]\n",
    "SPDC_l1norm_L2_lbda2 = res_exp_lbda2['L2_loss'][1,:,1]\n",
    "HiLa_l1norm_L2_lbda2 = res_exp_lbda2['L2_loss'][0,:,1]\n",
    "\n",
    "var = ((HiLa_l1norm_L1_lbda2[-1]/HiLa_l1norm_L1_lbda2[0]) - 1)\n",
    "print('First Layer HiLa high_lbda_1 / low_lbda_1 : {0:0.2f} %'.format(var*100))\n",
    "\n",
    "var = ((SPDC_l1norm_L1_lbda2[-1]/SPDC_l1norm_L1_lbda2[0]) - 1)\n",
    "print('First Layer SDPC high_lbda_1 / low_lbda_1 : {0:0.2f} %'.format(var*100))\n",
    "\n",
    "var = ((HiLa_l1norm_L2_lbda2[-1]/HiLa_l1norm_L2_lbda2[0]) - 1)\n",
    "print('Second Layer HiLa high_lbda_1 / low_lbda_1 : {0:0.2f} %'.format(var*100))\n",
    "\n",
    "var = ((SPDC_l1norm_L2_lbda2[-1]/SPDC_l1norm_L2_lbda2[0]) - 1)\n",
    "print('Second Layer SDPC high_lbda_1 / low_lbda_1 : {0:0.2f} %'.format(var*100))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting the curve\n",
    "save_fig =  False\n",
    "\n",
    "med_lbda1_SDPC = res_exp_lbda1['it'][1,:]\n",
    "med_lbda1_HiLa = res_exp_lbda1['it'][0,:]\n",
    "\n",
    "out = plt.plot(range_lbda1, med_lbda1_SDPC, label='SDPC', color=cmap1(1), linewidth=3)\n",
    "out = plt.plot(range_lbda1, med_lbda1_HiLa, label='Hi-La', color=cmap2(5), linewidth=3)\n",
    "plt.xticks(range_lbda1,fontsize=15)\n",
    "plt.yticks([0,35,70,105,140], fontsize=15)\n",
    "\n",
    "plt.tick_params(axis='both', which='major', pad=5)\n",
    "plt.title('iii) - MNIST', fontsize=15)\n",
    "out = plt.xlabel(r\"$\\lambda_{1}$\", fontsize=15, labelpad=10)\n",
    "out = plt.ylabel(\"number of iterations\", fontsize=15, labelpad=10)\n",
    "\n",
    "if save_fig:\n",
    "\n",
    "    plt.savefig('Figure/MNIST_nbit_lbda1.png', bbox_inches = 'tight', pad_inches = 0.1, dpi=400)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "med_lbda2_SDPC = res_exp_lbda2['it'][1,:]\n",
    "med_lbda2_HiLa = res_exp_lbda2['it'][0,:]\n",
    "\n",
    "out = plt.plot(range_lbda2, med_lbda2_SDPC, label='SDPC', color=cmap1(1), linewidth=3)\n",
    "out = plt.plot(range_lbda2, med_lbda2_HiLa, label='Hi-La', color=cmap2(5), linewidth=3)\n",
    "plt.xticks(range_lbda2,fontsize=15)\n",
    "plt.yticks([0,35,70,105,140], fontsize=15)\n",
    "\n",
    "plt.tick_params(axis='both', which='major', pad=5)\n",
    "plt.title('iii) - MNIST', fontsize=15)\n",
    "out = plt.xlabel(r\"$\\lambda_{2}$\", fontsize=15, labelpad=10)\n",
    "out = plt.ylabel(\"number of iterations\", fontsize=15, labelpad=10)\n",
    "\n",
    "if save_fig:\n",
    "\n",
    "    plt.savefig('Figure/MNIST_nbit_lbda2png', bbox_inches = 'tight', pad_inches = 0.1, dpi=400)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Savings/MNIST/MNIST_[0.20,0.30]_b=0.pkl'\n",
    "with open(path, 'rb') as file:\n",
    "    res_Hila = pickle.load(file)\n",
    "\n",
    "path = 'Savings/MNIST/MNIST_[0.20,0.30]_b=1.pkl'\n",
    "with open(path, 'rb') as file:\n",
    "    res_SDPC = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cmap1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c2608152ac80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mres_SDPC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l2_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mres_SDPC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l1_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreco_SDPC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2L_SPC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreco_Hila\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Hi-La'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cmap1' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_fig = False\n",
    "fig1, ax1 = plt.subplots()\n",
    "\n",
    "x  = np.arange(10,2500,20)\n",
    "idx = np.arange(10,25000,200)\n",
    "\n",
    "reco_Hila = res_Hila['l2_loss'][0] + 0.2*res_Hila['l1_loss'][0] + \\\n",
    "#            res_Hila['l2_loss'][1] + 0.3*res_Hila['l1_loss'][1]\n",
    "reco_SDPC = res_SDPC['l2_loss'][0] + 0.2*res_SDPC['l1_loss'][0] + \\\n",
    "            res_SDPC['l2_loss'][1] + 0.3*res_SDPC['l1_loss'][1]\n",
    "\n",
    "out = ax1.plot(reco_SDPC[idx].detach().numpy(), label = '2L_SPC', color=cmap1(1), linewidth=3)\n",
    "out = ax1.plot(reco_Hila[idx].detach().numpy(), label='Hi-La', color=cmap2(5), linewidth=3)\n",
    "\n",
    "ax1.set_title('iii) - MNIST', fontsize=15)\n",
    "\n",
    "\n",
    "ax1.set_xticks([0,200,400,600,800,1000])\n",
    "ax1.set_xticklabels([1,200,400,600,800,1000],fontsize=15)\n",
    "#ax1.set_yscale('log')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yticks([80, 100, 200, 300])\n",
    "ax1.set_yticklabels([r'$8\\times10^1$',r'$1\\times10^2$',r'$2\\times10^2$', r'$3\\times10^3$'],fontsize=15)\n",
    "#ax1.set_yticklabels([r'$3\\times10^3$',r'$1\\times10^4$',r'$4\\times10^4$', r'$2\\times10^5$'],fontsize=15)\n",
    "out = ax1.set_xlabel(\"number of epochs\", fontsize=15, labelpad=10)\n",
    "out = ax1.set_ylabel(\"total cost\", fontsize=15, labelpad=10)\n",
    "\n",
    "if save_fig :\n",
    "    plt.savefig('Figure/STL10_Loss_training.png', bbox_inches = 'tight', pad_inches = 0.1, dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
